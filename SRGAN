import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchvision.utils import save_image
import matplotlib.pyplot as plt
from PIL import Image
import torchvision.models as models

# Set random seeds for reproducibility
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)
torch.cuda.manual_seed_all(42)

# Check for GPU availability
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Custom Dataset for Brain Tumor MRI
class BrainTumorDataset(Dataset):
    def _init_(self, root_dir, scale_factor=4, transform=None, low_res_transform=None):
        """
        Args:
            root_dir (string): Directory with all the images.
            scale_factor (int): Factor to downscale for creating low-res images
            transform (callable, optional): Optional transform for high-res images
            low_res_transform (callable, optional): Optional transform for low-res images
        """
        self.root_dir = root_dir
        self.scale_factor = scale_factor
        self.transform = transform
        self.low_res_transform = low_res_transform
        
        # Get all image files
        self.image_files = []
        for category in ['glioma', 'meningioma', 'notumor', 'pituitary']:
            category_dir = os.path.join(root_dir, category)
            if os.path.isdir(category_dir):
                for img_name in os.listdir(category_dir):
                    if img_name.endswith(('.jpg', '.jpeg', '.png')):
                        self.image_files.append(os.path.join(category_dir, img_name))
    
    def _len_(self):
        return len(self.image_files)
    
    def _getitem_(self, idx):
        img_path = self.image_files[idx]
        
        # Load image
        hr_image = Image.open(img_path).convert('RGB')
        
        # Apply high-res transform if provided
        if self.transform:
            hr_image = self.transform(hr_image)
        
        # Create low-res version (downscale and upscale to simulate low quality)
        width, height = hr_image.size if isinstance(hr_image, Image.Image) else (hr_image.shape[2], hr_image.shape[1])
        lr_size = (width // self.scale_factor, height // self.scale_factor)
        
        if isinstance(hr_image, Image.Image):
            lr_image = hr_image.resize(lr_size, Image.BICUBIC)
            lr_image = lr_image.resize((width, height), Image.BICUBIC)
            
            if self.low_res_transform:
                lr_image = self.low_res_transform(lr_image)
        else:
            # If hr_image is already a tensor from transform
            # Convert tensor back to PIL for resizing
            to_pil = transforms.ToPILImage()
            to_tensor = transforms.ToTensor()
            
            lr_image = to_pil(hr_image)
            lr_image = lr_image.resize(lr_size, Image.BICUBIC)
            lr_image = lr_image.resize((width, height), Image.BICUBIC)
            lr_image = to_tensor(lr_image)
            
            if self.low_res_transform:
                lr_image = self.low_res_transform(lr_image)
        
        return {'lr': lr_image, 'hr': hr_image}

# Generator Network
class ResidualBlock(nn.Module):
    def _init_(self, channels):
        super(ResidualBlock, self)._init_()
        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(channels)
        self.prelu = nn.PReLU()
        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(channels)
        
    def forward(self, x):
        residual = x
        out = self.prelu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += residual
        return out

class UpsampleBlock(nn.Module):
    def _init_(self, in_channels, scale_factor):
        super(UpsampleBlock, self)._init_()
        self.conv = nn.Conv2d(in_channels, in_channels * scale_factor ** 2, kernel_size=3, padding=1)
        self.pixel_shuffle = nn.PixelShuffle(scale_factor)
        self.prelu = nn.PReLU()
        
    def forward(self, x):
        x = self.conv(x)
        x = self.pixel_shuffle(x)
        x = self.prelu(x)
        return x

class Generator(nn.Module):
    def _init_(self, scale_factor=4, num_residual_blocks=16):
        super(Generator, self)._init_()
        
        # First layer
        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)
        self.prelu = nn.PReLU()
        
        # Residual blocks
        res_blocks = []
        for _ in range(num_residual_blocks):
            res_blocks.append(ResidualBlock(64))
        self.res_blocks = nn.Sequential(*res_blocks)
        
        # Second conv layer after residual blocks
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.bn = nn.BatchNorm2d(64)
        
        # Upsampling layers
        upsample_layers = []
        for _ in range(int(np.log2(scale_factor))):
            upsample_layers.append(UpsampleBlock(64, 2))
        self.upsampling = nn.Sequential(*upsample_layers)
        
        # Final output layer
        self.conv3 = nn.Conv2d(64, 3, kernel_size=9, padding=4)
        self.tanh = nn.Tanh()
        
    def forward(self, x):
        # Initial convolution
        x = self.prelu(self.conv1(x))
        
        # Residual blocks
        residual = x
        x = self.res_blocks(x)
        
        # Second convolution and skip connection
        x = self.bn(self.conv2(x))
        x += residual
        
        # Upsampling
        x = self.upsampling(x)
        
        # Final convolution
        x = self.tanh(self.conv3(x))
        
        return x

# Discriminator Network
class Discriminator(nn.Module):
    def _init_(self):
        super(Discriminator, self)._init_()
        
        # Feature extraction part
        self.features = nn.Sequential(
            # input size: 3 x 256 x 256
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            
            # Strided convolutions for downsampling
            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
        )
        
        # Classification layer
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1024, 1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# Content Loss (VGG-based perceptual loss)
class VGGLoss(nn.Module):
    def _init_(self):
        super(VGGLoss, self)._init_()
        vgg = models.vgg19(pretrained=True)
        # Use features before activation
        self.feature_extractor = nn.Sequential(*list(vgg.features)[:36]).eval()
        # Freeze VGG parameters
        for param in self.feature_extractor.parameters():
            param.requires_grad = False
            
    def forward(self, sr, hr):
        # Extract features
        sr_features = self.feature_extractor(sr)
        hr_features = self.feature_extractor(hr)
        
        # Calculate L1 loss between features
        loss = nn.L1Loss()(sr_features, hr_features)
        return loss

# Training function
def train_srgan(dataloader, generator, discriminator, epochs, device, save_dir):
    # Loss functions
    content_criterion = VGGLoss().to(device)
    adversarial_criterion = nn.BCELoss().to(device)
    mse_loss = nn.MSELoss().to(device)
    
    # Optimizers
    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001)
    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001)
    
    # Training loop
    generator.train()
    discriminator.train()
    
    g_losses = []
    d_losses = []
    
    for epoch in range(epochs):
        epoch_g_loss = 0
        epoch_d_loss = 0
        
        for i, batch in enumerate(dataloader):
            # Move data to device
            lr_images = batch['lr'].to(device)
            hr_images = batch['hr'].to(device)
            
            # Adversarial ground truths
            real_labels = torch.ones(lr_images.size(0), 1).to(device)
            fake_labels = torch.zeros(lr_images.size(0), 1).to(device)
            
            #########################
            # Train Discriminator
            #########################
            optimizer_D.zero_grad()
            
            # Generate super-resolution images
            sr_images = generator(lr_images)
            
            # Real loss
            real_outputs = discriminator(hr_images)
            d_real_loss = adversarial_criterion(real_outputs, real_labels)
            
            # Fake loss
            fake_outputs = discriminator(sr_images.detach())
            d_fake_loss = adversarial_criterion(fake_outputs, fake_labels)
            
            # Total discriminator loss
            d_loss = d_real_loss + d_fake_loss
            
            d_loss.backward()
            optimizer_D.step()
            
            #########################
            # Train Generator
            #########################
            optimizer_G.zero_grad()
            
            # Content loss (MSE and VGG perceptual loss)
            content_loss = mse_loss(sr_images, hr_images)
            perceptual_loss = content_criterion(sr_images, hr_images)
            
            # Adversarial loss
            fake_outputs = discriminator(sr_images)
            adversarial_loss = adversarial_criterion(fake_outputs, real_labels)
            
            # Total generator loss
            g_loss = content_loss + 0.006 * adversarial_loss + 0.1 * perceptual_loss
            
            g_loss.backward()
            optimizer_G.step()
            
            # Save losses for plotting
            epoch_g_loss += g_loss.item()
            epoch_d_loss += d_loss.item()
            
            # Print status
            if i % 50 == 0:
                print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(dataloader)}], '
                      f'G Loss: {g_loss.item():.4f}, D Loss: {d_loss.item():.4f}')
        
        # Calculate average epoch loss
        epoch_g_loss /= len(dataloader)
        epoch_d_loss /= len(dataloader)
        
        g_losses.append(epoch_g_loss)
        d_losses.append(epoch_d_loss)
        
        # Save model checkpoints
        if (epoch+1) % 10 == 0:
            torch.save(generator.state_dict(), os.path.join(save_dir, f'generator_epoch_{epoch+1}.pth'))
            torch.save(discriminator.state_dict(), os.path.join(save_dir, f'discriminator_epoch_{epoch+1}.pth'))
            
            # Save sample images
            generator.eval()
            with torch.no_grad():
                # Sample random images from dataloader
                sample_batch = next(iter(dataloader))
                lr_sample = sample_batch['lr'].to(device)
                hr_sample = sample_batch['hr'].to(device)
                sr_sample = generator(lr_sample)
                
                # Save images
                for j in range(min(5, lr_sample.size(0))):  # Save first 5 images
                    # Denormalize and save
                    save_image(lr_sample[j], os.path.join(save_dir, f'epoch_{epoch+1}sample{j}_LR.png'))
                    save_image(sr_sample[j], os.path.join(save_dir, f'epoch_{epoch+1}sample{j}_SR.png'))
                    save_image(hr_sample[j], os.path.join(save_dir, f'epoch_{epoch+1}sample{j}_HR.png'))
            
            generator.train()
    
    # Plot loss curves
    plt.figure(figsize=(10, 5))
    plt.plot(g_losses, label='Generator Loss')
    plt.plot(d_losses, label='Discriminator Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('SRGAN Training Loss')
    plt.savefig(os.path.join(save_dir, 'training_loss.png'))
    
    # Save final models
    torch.save(generator.state_dict(), os.path.join(save_dir, 'generator_final.pth'))
    torch.save(discriminator.state_dict(), os.path.join(save_dir, 'discriminator_final.pth'))
    
    return generator, discriminator

# Function to test model on validation data
def test_srgan(model, test_dataloader, device, save_dir):
    model.eval()
    
    # Calculate PSNR
    psnr_values = []
    ssim_values = []
    
    with torch.no_grad():
        for i, batch in enumerate(test_dataloader):
            lr_images = batch['lr'].to(device)
            hr_images = batch['hr'].to(device)
            
            # Generate SR images
            sr_images = model(lr_images)
            
            # Calculate PSNR for each image in batch
            for j in range(lr_images.size(0)):
                # Convert to numpy for PSNR calculation
                sr_np = sr_images[j].cpu().numpy().transpose(1, 2, 0)
                hr_np = hr_images[j].cpu().numpy().transpose(1, 2, 0)
                
                # Clip values to [0, 1]
                sr_np = np.clip(sr_np, 0, 1)
                hr_np = np.clip(hr_np, 0, 1)
                
                # Calculate PSNR
                mse = np.mean((sr_np - hr_np) ** 2)
                if mse == 0:
                    psnr = 100
                else:
                    max_pixel = 1.0
                    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
                
                psnr_values.append(psnr)
                
            # Save sample images
            if i % 10 == 0:
                for j in range(min(5, lr_images.size(0))):
                    save_image(lr_images[j], os.path.join(save_dir, f'test_sample_{i}_{j}_LR.png'))
                    save_image(sr_images[j], os.path.join(save_dir, f'test_sample_{i}_{j}_SR.png'))
                    save_image(hr_images[j], os.path.join(save_dir, f'test_sample_{i}_{j}_HR.png'))
    
    # Calculate average PSNR
    avg_psnr = sum(psnr_values) / len(psnr_values)
    print(f'Average PSNR: {avg_psnr:.2f} dB')
    
    return avg_psnr

# Main function
def main():
    # Dataset paths
    data_root = './Brain_Tumor_MRI_Dataset'
    train_dir = os.path.join(data_root, 'Training')
    test_dir = os.path.join(data_root, 'Testing')
    
    # Create output directory
    output_dir = './SRGAN_Brain_Tumor_Output'
    os.makedirs(output_dir, exist_ok=True)
    
    # Image transformations
    train_hr_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
    ])
    
    # Create datasets
    train_dataset = BrainTumorDataset(train_dir, transform=train_hr_transform)
    test_dataset = BrainTumorDataset(test_dir, transform=train_hr_transform)
    
    # Create dataloaders
    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)
    
    # Initialize models
    generator = Generator().to(device)
    discriminator = Discriminator().to(device)
    
    # Train the models
    generator, discriminator = train_srgan(
        train_dataloader, 
        generator, 
        discriminator, 
        epochs=100,  # Adjust based on your computation resources
        device=device,
        save_dir=output_dir
    )
    
    # Test the trained model
    avg_psnr = test_srgan(generator, test_dataloader, device, output_dir)
    
    # Save test results
    with open(os.path.join(output_dir, 'test_results.txt'), 'w') as f:
        f.write(f'Average PSNR: {avg_psnr:.2f} dB\n')
    
    print("SRGAN training and testing completed!")

if _name_ == "_main_":
    main()

</antArtifact><antArtifact identifier="srgan-usage-guide" type="text/markdown" language="" title="SR-GAN for Brain Tumor MRI: Usage Guide">
# Brain Tumor MRI Super-Resolution Guide

This guide explains how to use the SR-GAN implementation I've created to enhance brain tumor MRI images for better tumor detection and analysis.

## Overview

The SR-GAN (Super-Resolution Generative Adversarial Network) is designed to enhance low-resolution MRI scans to higher resolution versions, preserving important pathological features while improving image quality. This is particularly useful for:

1. Enhancing older or lower-quality MRI scans
2. Improving tumor boundary detection
3. Enhancing small tumor features that might be missed in lower resolution images
4. Creating more consistent image quality across datasets for machine learning applications

## Dataset Structure

The code expects the Brain Tumor MRI Dataset to be organized as follows:


Brain_Tumor_MRI_Dataset/
├── Training/
│   ├── glioma/
│   ├── meningioma/
│   ├── notumor/
│   └── pituitary/
└── Testing/
    ├── glioma/
    ├── meningioma/
    ├── notumor/
    └── pituitary/


## Installation Requirements

Before running the SR-GAN, ensure you have the following dependencies installed:

bash
pip install torch torchvision numpy matplotlib pillow scikit-image tqdm


## Usage Instructions

1. *Download the Dataset*: Download the Brain Tumor MRI dataset from Kaggle and extract it.

2. *Setup Directory Structure*: Make sure your directory structure matches the one described above.

3. *Run the SR-GAN Training*:
   bash
   python srgan_brain_tumor.py
   

4. *Monitor Training Progress*: During training, you'll see progress updates, and sample images will be saved periodically in the output directory.

5. *Evaluate Results*: After training, the model will be evaluated on the test set, and performance metrics will be saved in test_results.txt.

## Customization Options

You can customize the SR-GAN implementation by modifying these parameters:

- *Scale Factor*: Change the upscaling factor (default is 4x)
  python
  train_dataset = BrainTumorDataset(train_dir, scale_factor=2)  # For 2x upscaling
  

- *Image Size*: Adjust the target image resolution
  python
  transforms.Resize((512, 512))  # For higher resolution outputs
  

- *Training Parameters*: Adjust learning rate, batch size, or number of epochs
  python
  optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)  # Increase learning rate
  train_dataloader = DataLoader(train_dataset, batch_size=8)  # Smaller batch size
  generator, discriminator = train_srgan(..., epochs=50)  # Fewer epochs
  

## Practical Applications

1. *Pre-processing for Segmentation Models*: Use the SR-GAN to enhance images before feeding them to tumor segmentation models for better boundary detection.

2. *Data Augmentation*: Generate high-quality synthetic data by enhancing existing images when training data is limited.

3. *Retrospective Enhancement*: Improve older scans in existing patient records for more consistent analysis.

4. *Transfer Learning*: The pre-trained generator can be fine-tuned on other medical imaging datasets with limited data.

## Model Architecture Details

The implementation uses a modern SR-GAN architecture with:

- *Generator*: Deep residual network with 16 residual blocks and pixel shuffle upsampling
- *Discriminator*: Convolutional network with strided convolutions for downsampling
- *Loss Function*: Combined loss including:
  - Pixel-wise MSE loss for structural similarity
  - Adversarial loss from the discriminator
  - Perceptual loss using VGG19 feature maps to preserve texture details

## Troubleshooting

- *Memory Issues*: If you encounter CUDA out-of-memory errors, try reducing the batch size or image dimensions
- *Slow Training*: Consider using a smaller subset of the data for initial experiments
- *Poor Results*: Try adjusting the balance between perceptual, adversarial, and content losses

## Using Pre-trained Models

To use a pre-trained model for enhancing new images:

python
# Load pre-trained generator
generator = Generator().to(device)
generator.load_state_dict(torch.load('SRGAN_Brain_Tumor_Output/generator_final.pth'))
generator.eval()

# Enhance a single image
from PIL import Image
from torchvision import transforms

# Load and prepare input image
img = Image.open('path_to_image.jpg').convert('RGB')
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
])
input_tensor = transform(img).unsqueeze(0).to(device)

# Generate super-resolution image
with torch.no_grad():
    output_tensor = generator(input_tensor)

# Save enhanced image
save_image(output_tensor.squeeze(0), 'enhanced_image.png')


## References

- Wang, X. et al. (2018). ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks.
- Ledig, C. et al. (2017). Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.
